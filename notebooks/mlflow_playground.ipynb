{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow Playground\n",
    "\n",
    "In this notebook, we explored MLflow's (and hyperopt's) functionality for logging models and hyperparameter optimization until a satisfactory solution was found for our own project.\n",
    "The example below uses a toy dataset (wine quality)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import hyperopt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import mlflow\n",
    "\n",
    "sys.path.append(\"../functions\")\n",
    "from mlflow_utils import start_mlflow_server, mlflow_train_keras_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load toy data\n",
    "data = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-white.csv\",\n",
    "    sep=\";\",\n",
    ")\n",
    "\n",
    "#split the data into training, validation, and test sets\n",
    "train, test = train_test_split(data, test_size=0.25, random_state=42)\n",
    "X_tv = train.drop([\"quality\"], axis=1).values\n",
    "y_tv = train[[\"quality\"]].values.ravel()\n",
    "X_test = test.drop([\"quality\"], axis=1).values\n",
    "y_test = test[[\"quality\"]].values.ravel()\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_tv, y_tv, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start the mlflow server\n",
    "#it can be accessed in your browser at http://127.0.0.1:5000\n",
    "start_mlflow_server(experiment_name=\"example_experiment\") #take care to choose the proper experiment name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training function\n",
    "To perform model training and hyperparameter optimization, create a function like the one below and thereafter call the custom function `mlflow_train_keras_model()` from `mlflow_utils` with a pointer to the previously created function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function similar to this one (should have the same parameter list and return value)\n",
    "#supply your own search_params (see below) and don't worry about the components variable\n",
    "\n",
    "def train_model_sample(search_params, components, train_data, valid_data):\n",
    "\n",
    "    #define some model\n",
    "    mean = np.mean(train_data[0], axis=0)\n",
    "    var = np.var(train_data[0], axis=0)\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.Input([train_data[0].shape[1]]),\n",
    "            tf.keras.layers.Normalization(mean=mean, variance=var),\n",
    "            tf.keras.layers.Dense(search_params[\"n_dense_neurons\"], activation=\"relu\"), #wherever applicable, insert hyperparameters from the search_params dict (your search space)\n",
    "            tf.keras.layers.Dense(1),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    #compile model\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.SGD(\n",
    "            learning_rate=search_params[\"lr\"], momentum=search_params[\"momentum\"]\n",
    "        ),\n",
    "        loss=\"mean_squared_error\",\n",
    "        metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
    "    )\n",
    "\n",
    "    #train model with MLflow tracking\n",
    "    with mlflow.start_run(nested=True):\n",
    "        history = model.fit(\n",
    "            train_data[0],\n",
    "            train_data[1],\n",
    "            validation_data=(valid_data[0], valid_data[1]),\n",
    "            epochs=10,\n",
    "            batch_size=64,\n",
    "            callbacks=[components[\"mlflow_logger\"]] #please include this callback so epoch-wise performance gets logged by mlflow\n",
    "        )\n",
    "        #evaluate the model\n",
    "        eval_result = model.evaluate(valid_data[0], valid_data[1], batch_size=64)\n",
    "        val_loss = eval_result[1]\n",
    "\n",
    "        #log parameters and results\n",
    "        mlflow.log_params(search_params)\n",
    "        mlflow.log_metric(\"final_val_loss\", val_loss)\n",
    "\n",
    "        #log model\n",
    "        mlflow.tensorflow.log_model(model, \"model\")\n",
    "\n",
    "        #MUST return \"loss\" and \"status\" in this dictionary\n",
    "        return {\"loss\": val_loss, \"status\": hyperopt.STATUS_OK, \"model\": model} \n",
    "\n",
    "\n",
    "#define a hyperopt search space for hyperparameter optimization\n",
    "#more options can be found here: https://github.com/hyperopt/hyperopt/wiki/FMin#21-parameter-expressions\n",
    "search_space = {\n",
    "    \"lr\": hyperopt.hp.loguniform(\"lr\", np.log(1e-5), np.log(1e-1)),\n",
    "    \"momentum\": hyperopt.hp.uniform(\"momentum\", 0.0, 1.0),\n",
    "    \"n_dense_neurons\": hyperopt.hp.uniformint(\"n_dense_neurons\", 16, 512),\n",
    "}\n",
    "\n",
    "#create some tags for the current run (must be dictionary, but you can freely name those key-value pairs)\n",
    "#we should probably decide a set of tags that need to be included\n",
    "tags = {\n",
    "    \"model_type\": \"Sequential\",\n",
    "    \"data_amount\": \"all\",\n",
    "    \"optimizer\": \"SGD\"\n",
    "}\n",
    "\n",
    "#run the model fit with hyperparameter search\n",
    "#the returned run object can be used to extract the best model of this run\n",
    "my_run = mlflow_train_keras_model(\n",
    "    train_fn=train_model_sample,\n",
    "    train_data=(X_train, y_train),\n",
    "    valid_data=(X_valid, y_valid),\n",
    "    search_space=search_space,\n",
    "    n_evals=5,\n",
    "    mlflow_tags=tags\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supplementary actions after model fitting\n",
    "Registering models and subsequently loading them (from the MLflow database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving and loading models\n",
    "\n",
    "#register model from current run\n",
    "run_id = my_run.info.run_id\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "model_name = \"my_best_model\"\n",
    "mlflow.register_model(model_uri=model_uri, name=model_name)\n",
    "\n",
    "#load model from run\n",
    "loaded_model_from_run = mlflow.tensorflow.load_model(model_uri)\n",
    "\n",
    "#load registered model\n",
    "model_version = 1\n",
    "model_uri2 =  f\"models:/{model_name}/{model_version}\"\n",
    "loaded_model_from_registry = mlflow.tensorflow.load_model(model_uri2)\n",
    "\n",
    "#use model as desired\n",
    "y_test_pred1 = loaded_model_from_run.predict(X_test)\n",
    "y_test_pred2 = loaded_model_from_registry.predict(X_test)\n",
    "assert((y_test_pred1 == y_test_pred2).all())\n",
    "mean_squared_error(y_test, y_test_pred1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
